{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2a0189",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49c4ea",
   "metadata": {},
   "source": [
    "Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Input, Dropout, MaxPooling2D, Flatten, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Flatten, Reshape, Cropping2D, LeakyReLU, BatchNormalization, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import datasets, Model\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "from collections import OrderedDict\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML\n",
    "import IPython\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_clustering import *\n",
    "from utils.utils_plot import *\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to plot reconstructions\n",
    "\n",
    "def vis_reconstructions(ds_newtest):\n",
    "    # Plot the initial frame. \n",
    "    # Get a handle on the figure and the axes\n",
    "    lp = ['X_valid','Reconstructions']\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2,\n",
    "                            subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "                            figsize=(12, 4))\n",
    "\n",
    "    # axs is a 2 dimensional array of `GeoAxes`.  We will flatten it into a 1-D array\n",
    "    axs = axs.flatten()\n",
    "    cax = ds_newtest.isel(time=0)[lp[0]].plot(ax=axs[0],\n",
    "                                              transform=ccrs.PlateCarree(),\n",
    "                                              cmap=plt.cm.RdBu_r,\n",
    "                                              add_colorbar=False)\n",
    "    axs[0].coastlines('50m', edgecolor='black', linewidth=0.75)\n",
    "\n",
    "    cax1 = ds_newtest.isel(time=0)[lp[1]].plot(ax=axs[1],\n",
    "                                               transform=ccrs.PlateCarree(),\n",
    "                                               cmap=plt.cm.RdBu_r,\n",
    "                                               add_colorbar=False)\n",
    "    axs[1].coastlines('50m', edgecolor='black', linewidth=0.75)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    def animate(frame):\n",
    "        cax.set_array(ds_newtest[lp[0]][frame,:,:].values.flatten())\n",
    "        axs[0].set_title(\"Time = \" + str(ds_newtest[lp[0]].coords['time'].values[frame])[:13])\n",
    "        cax1.set_array(ds_newtest[lp[1]][frame,:,:].values.flatten())\n",
    "        axs[1].set_title(\"Time = \" + str(ds_newtest[lp[1]].coords['time'].values[frame])[:13])\n",
    "    # Finally, we use the animation module to create the animation.\n",
    "    \n",
    "    ani = animation.FuncAnimation(\n",
    "        fig,             # figure\n",
    "        animate,         # name of the function above\n",
    "        frames=40,       # Could also be iterable or list\n",
    "        interval=200     # ms between frames\n",
    "    )\n",
    "    \n",
    "    display(HTML(ani.to_jshtml()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7d944",
   "metadata": {},
   "source": [
    "## Data:\n",
    "\n",
    "In this case we are working with geopotential height at 500hPa: **z500**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = os.path.join(os.getcwd(), '..', 'data')\n",
    "G = 9.80665 \n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8160b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_dat = xr.open_mfdataset(f'{DATADIR}/ERA5/geopotential/grid1/*.nc', combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252fe1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = gp_dat.sel(time=slice(DATE_START, DATE_END), level=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dimensions\n",
    "z500 = rename_dimensions_variables(z500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff44300",
   "metadata": {},
   "outputs": [],
   "source": [
    "z500.z.values = z500.z.values/G\n",
    "lon = z500.lon\n",
    "lat = z500.lat\n",
    "mvar = 'z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gridded data\n",
    "ds_z = z500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates\n",
    "lats = ds_z.lat\n",
    "lons = ds_z.lon\n",
    "time = ds_z.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "ds_mean = ds_z.mean(dim='time')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1,\n",
    "                        subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "                        figsize=(11, 8.5))\n",
    "cs = axs.contourf(lon, lat, ds_mean['z'], cmap=plt.cm.RdBu_r,\n",
    "                  transform=ccrs.PlateCarree(), extend='both')\n",
    "axs.coastlines('50m', edgecolor='black', linewidth=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957698dd",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "Apply Kmeans previously, so this can help us to make some interpretation of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330df48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "K_labels = KCluster_v2(ds_z, 'z', 8)  # let's start with 8 clusters\n",
    "day_clus, myclusters, nfreq = getclus_v2(K_labels, ds_z, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee628f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualise the clusters\n",
    "visualize_cluster(myclusters, nfreq, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_train = K_labels[0:13514]\n",
    "y_labels_test = K_labels[13514:15341]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbfad34",
   "metadata": {},
   "source": [
    "## Data preprocess: splitting into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84117817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the data generator all variables have to be merged into a single dataset.\n",
    "datasets = [ds_z]\n",
    "ds = xr.merge(datasets)\n",
    "ds.expand_dims('level', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test, then I will use DataGenerator class to get the validation\n",
    "# I am going to use only Z500 for now:\n",
    "ds_train = ds.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                             '{}-12-31'.format(YY_TRAIN[1])))\n",
    "ds_test = ds.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                            '{}-12-31'.format(YY_TEST[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear session and set tf seed\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1440fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we need a dictionary for all the variables and levels we want to extract from the dataset\n",
    "dic = OrderedDict({'z': None})\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ead21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and test data generator. Use the train mean and std for validation as well.\n",
    "dg_train = DataGenerator(ds_train.sel(time=slice('1979', '2015')), dic, batch_size=bs, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train.mean, dg_train.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now also a generator for testing. Impartant: Shuffle must be False!\n",
    "dg_test = DataGenerator(ds_test, dic, batch_size=bs, mean=dg_train.mean, std=dg_train.std, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_train = xr.DataArray(dg_train.data)\n",
    "X_test = xr.DataArray(dg_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ad97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = np.array(X_train)\n",
    "X_test_input = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9584e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_input.shape)\n",
    "print(X_test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b076e",
   "metadata": {},
   "source": [
    "# Building a simple AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer of the neural network, which will be our  dataset\n",
    "n_size = X_train_input.shape[1:]\n",
    "n_code = 12\n",
    "activation_function = 'linear'\n",
    "optimizer = 'adam'\n",
    "n_flatsize = np.product(n_size)\n",
    "print(n_size, n_code, n_flatsize)\n",
    "latent_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE\n",
    "# Defines encoder\n",
    "stacked_encoder = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=n_size),\n",
    "        keras.layers.Dense(128, activation=activation_function),\n",
    "        keras.layers.Dense(latent_size, activation=activation_function),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ade424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decoder\n",
    "stacked_decoder = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(128, activation=activation_function,\n",
    "                           input_shape=[latent_size]),\n",
    "        keras.layers.Dense(n_flatsize),\n",
    "        keras.layers.Reshape(n_size)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac52421",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ce08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7988e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "stacked_ae.compile(loss='mean_squared_error',\n",
    "                   optimizer=optimizer,\n",
    "                   metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68d2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = stacked_ae.fit(X_train_input,\n",
    "                         X_train_input,\n",
    "                         epochs=10,\n",
    "                         validation_data=(X_test_input, X_test_input),\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfcbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_mse = history.history['val_mse'][-1]\n",
    "last_mae = history.history['val_mae'][-1]\n",
    "print(last_mse, last_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b553e",
   "metadata": {},
   "source": [
    "## Visualizing in the latent space\n",
    "For that we will make use of the clusters calculated above \n",
    "A total of 8 Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = stacked_encoder.predict(X_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dce1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = stacked_decoder.predict(encoded_imgs)\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global flag\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    latent_vector = np.array([[ix, iy]])\n",
    "\n",
    "    decoded_img = stacked_decoder.predict(latent_vector)\n",
    "\n",
    "    ds_newtest = ds_test.z[0, :, :]\n",
    "    ds_newtest['X_valid'] = (('lat', 'lon'), decoded_img[0, :, :, 0])\n",
    "    ds_newtest['X_valid'].plot(ax=ax[1], cmap=plt.cm.RdBu_r, add_colorbar=False)\n",
    "    ax[1].coastlines('50m', edgecolor='black', linewidth=0.75)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f309c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "ax[0].scatter(encoded_imgs[:, 0], encoded_imgs[:, 1],\n",
    "              c=np.array(y_labels_test.cluster), s=25, cmap='tab10')\n",
    "cid = fig.canvas.mpl_connect('motion_notify_event', onclick)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054c8c1",
   "metadata": {},
   "source": [
    "# Look at the reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b863fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings = stacked_encoder.predict(X_test_input)\n",
    "codings.shape  # this are similar as the PCA (the first that we kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa41ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = stacked_ae.predict(X_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38344710",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with the original, so we can use the information about the coordinates\n",
    "ds_newtest = ds_test.z\n",
    "ds_newtest['X_valid'] = (('time', 'lat', 'lon'), X_test_input[:, :, :, 0])\n",
    "ds_newtest['Reconstructions'] = (('time', 'lat', 'lon'), reconstructions[:, :, :, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff86df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_reconstructions(ds_newtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743891d",
   "metadata": {},
   "source": [
    "## Convolutional AutoEncoder \n",
    "Building a CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "N, H, W, S = X_train_input.shape\n",
    "input_img = Input(shape=(H, W, S))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad27ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "decoded = Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
    "\n",
    "# Crop\n",
    "h, w = decoded.shape.as_list()[1:3]\n",
    "dh = h - H  # deltas to be cropped away\n",
    "dw = w - W\n",
    "decoded_cropping = Cropping2D(cropping=((dh//2, dh-dh//2), (dw//2, dw-dw//2)))(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b56b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_autoencoder = Model(input_img, decoded_cropping)\n",
    "cae_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cae_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b08a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_cae = cae_autoencoder.fit(X_train_input,\n",
    "                               X_train_input,\n",
    "                               epochs=10,\n",
    "                               validation_data=(X_test_input, X_test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_cae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions_cae = cae_autoencoder.predict(X_test_input)\n",
    "reconstructions_cae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907efb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions_cae2 = reconstructions_cae[:, :, :, 0]\n",
    "reconstructions_cae2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77685ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ds_newtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1502282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the existing data to compare with\n",
    "ds_newtest = ds_test.z\n",
    "ds_newtest['X_valid'] = (('time','lat','lon'), X_test_input[:,:,:,0])\n",
    "ds_newtest['Reconstructions'] = (('time','lat','lon'), reconstructions_cae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_reconstructions(ds_newtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ccb1f",
   "metadata": {},
   "source": [
    "## Now, let's try CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb39643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will crop first two coordinates\n",
    "X_train_input = X_train_input[:, 0:60, 0:120, :]\n",
    "X_test_input = X_test_input[:, 0:60, 0:120, :]\n",
    "X_train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dimensions\n",
    "encoded_size = 16\n",
    "base_depth = 32\n",
    "N, H, W, S = X_train_input.shape\n",
    "Nt, H, W, S = X_test_input.shape\n",
    "train_size = N\n",
    "test_size = Nt\n",
    "input_shape = H, W, S\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shufle the data\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(X_train_input)\n",
    "                 .shuffle(train_size).batch(base_depth))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(X_test_input)\n",
    "                .shuffle(test_size).batch(base_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd21152",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(X_train_input)\n",
    "test_data = np.array(X_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57566b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aee146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    # change names: z_mean =mu ; z_log_var = sigma (to be consistent)\n",
    "    mu, sigma = args\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.int_shape(mu)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    thre = K.random_uniform(shape=(batch, 1))\n",
    "    return mu + K.exp(0.5 * sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "\n",
    "def custom_loss(mu, sigma):\n",
    "    def loss(y_true, y_pred):\n",
    "        # mse loss\n",
    "        reconstruction_loss = K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True)\n",
    "        # kl loss\n",
    "        kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        #weight = 0.\n",
    "        return (reconstruction_loss + kl_loss)\n",
    "       # return reconstruction_loss + (weight * kl_loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ad196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder \n",
    "latent_dim = 2  # Number of latent dim parameters\n",
    "\n",
    "N, H, W, S = X_train_input.shape\n",
    "input_img = Input(shape=(H, W, S), name='encoder_input')\n",
    "\n",
    "x = Conv2D(16, 3, padding='same', activation=LeakyReLU(alpha=0.2), strides=2)(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, 3, padding='same', activation=LeakyReLU(alpha=0.2), strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, padding='same', activation=LeakyReLU(alpha=0.2))(x)   \n",
    "x = BatchNormalization()(x)   \n",
    "\n",
    "conv_shape = K.int_shape(x) # Shape of conv to be provided to decoder\n",
    "\n",
    "#Flatten\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation=LeakyReLU(alpha=0.2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba245f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two outputs, for latent mean and log variance (std. dev.)\n",
    "# Use these to sample random variables in latent space to which inputs are mapped. \n",
    "mu = Dense(latent_dim, name='latent_mu')(x)   #Mean values of encoded input\n",
    "sigma = Dense(latent_dim, name='latent_sigma')(x)  #Std dev. (variance) of encoded input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Lambda(sampling, output_shape=(latent_dim, ), name='z')([mu, sigma])\n",
    "\n",
    "# Z (lambda layer) will be the last layer in the encoder.\n",
    "# Define and summarize encoder model.\n",
    "vae_encoder = Model(input_img, [mu, sigma, z], name='encoder')\n",
    "print(vae_encoder.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder takes the latent vector as input\n",
    "decoder_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "\n",
    "# Need to start with a shape that can be remapped to original image shape as\n",
    "# we want our final utput to be same shape original input.\n",
    "# So, add dense layer with dimensions that can be reshaped to desired output shape\n",
    "x = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n",
    "# reshape to the shape of last conv. layer in the encoder, so we can\n",
    "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "# upscale (conv2D transpose) back to original shape\n",
    "# use Conv2DTranspose to reverse the conv layers defined in the encoder\n",
    "x = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2DTranspose(16, 3, padding='same', activation='relu', strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# Can add more conv2DTranspose layers, if desired.\n",
    "# Using sigmoid activation\n",
    "x = Conv2D(1, 3, padding='same', activation='relu', name='decoder_output')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Define and summarize decoder model\n",
    "vae_decoder = Model(decoder_input, x, name='decoder')\n",
    "vae_decoder.summary()\n",
    "# apply the decoder to the latent sample\n",
    "z_decoded = vae_decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e342e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VAE model\n",
    "outputs = vae_decoder(vae_encoder(input_img)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(input_img, outputs, name='vae')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=custom_loss(mu, sigma)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca388035",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "hist_vae = vae.fit(X_train_input, X_train_input,\n",
    "                   epochs=n_epochs,\n",
    "                   batch_size=batch_size,\n",
    "                   validation_data=(X_test_input, X_test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3a9bd",
   "metadata": {},
   "source": [
    "## Visualize in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6690469",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, _, _ = vae_encoder.predict(X_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds_newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick_vae(event):\n",
    "    global flag\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    latent_vector = np.array([[ix, iy]])\n",
    "\n",
    "    decoded_img = vae_decoder.predict(latent_vector)\n",
    "    # Create a new data set to add the decoded\n",
    "    ds_newtest = ds_test.z[0, 0:60, 0:120]\n",
    "    ds_newtest['X_valid'] = (('lat', 'lon'), decoded_img[0, :, :, 0])\n",
    "    ds_newtest['X_valid'].plot(ax=ax[1], cmap=plt.cm.RdBu_r, add_colorbar=False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7f780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "ax[0].scatter(mu[:, 0], mu[:, 1], c=np.array(y_labels_test.cluster), s=25, cmap='tab10')\n",
    "cid = fig.canvas.mpl_connect('motion_notify_event', onclick_vae)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the reconstructions\n",
    "reconstructions_vae = vae.predict(X_test_input)\n",
    "reconstructions_vae.shape\n",
    "reconstructions_vae2 = reconstructions_vae[:,:,:,0]\n",
    "reconstructions_vae2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de16f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the existing data to compare with\n",
    "ds_newtest = ds_test.z[:, 0:60, 0:120]\n",
    "ds_newtest['X_valid'] = (('time', 'lat', 'lon'), X_test_input[:, :, :, 0])\n",
    "ds_newtest['Reconstructions'] = (('time', 'lat', 'lon'), reconstructions_vae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_reconstructions(ds_newtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ffd28",
   "metadata": {},
   "source": [
    "## Comparing with PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcabc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_codings = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = np.array(X_train[:, :, :, 0])\n",
    "X_test_input = np.array(X_test[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skpca = PCA()\n",
    "skpca.fit(X_train_input.reshape(X_train_input.shape[0],\n",
    "                                X_train_input.shape[1] * X_train.shape[2]))\n",
    "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
    "    svd_solver='auto', tol=0.0, whiten=False)\n",
    "X_train_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1585a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs = skpca.transform(X_test_input.reshape(X_test_input.shape[0],\n",
    "                                           X_test_input.shape[1] * X_test_input.shape[2]))\n",
    "PCs.shape\n",
    "\n",
    "PCs = PCs[:, :n_codings]\n",
    "EOFs = skpca.components_\n",
    "EOFs = EOFs[:n_codings, :]\n",
    "print(EOFs.shape)\n",
    "print(PCs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21650866",
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_pca = np.dot(PCs, EOFs)\n",
    "recons_pca.shape\n",
    "recons_pca = recons_pca.reshape(recons_pca.shape[0],\n",
    "                                X_train_input.shape[1], X_train_input.shape[2])\n",
    "recons_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds_newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the existing data to compare with\n",
    "ds_newtest = ds_test.z\n",
    "ds_newtest['X_valid'] = (('time', 'lat', 'lon'), X_test_input[:, :, :])\n",
    "ds_newtest['Reconstructions'] = (('time', 'lat', 'lon'), recons_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_reconstructions(ds_newtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = X_train_input.reshape(X_train_input.shape[0],\n",
    "                                    X_train_input.shape[1]*X_train_input.shape[2])\n",
    "X_test_res = X_test_input.reshape(X_test_input.shape[0],\n",
    "                                  X_test_input.shape[1]*X_test_input.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "u_reduced = umap.UMAP(n_components=2).fit_transform(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(\n",
    "    x=u_reduced[:, 0],\n",
    "    y=u_reduced[:, 1],\n",
    "    c=y_label_train.cluster,\n",
    "    cmap=plt.cm.get_cmap('Spectral'),\n",
    "    alpha=0.4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
