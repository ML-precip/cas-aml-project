{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Import necessary modules and do some basic setup."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "from tensorflow import keras\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Custom utils\n",
    "from utils_data import *\n",
    "from utils_ml import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define some paths and constants."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Paths\n",
    "DATADIR = os.getcwd() + '/../data'\n",
    "\n",
    "# Some constants\n",
    "G = 9.80665\n",
    "CH_CENTER = [46.818, 8.228]\n",
    "CH_BOUNDING_BOX = [45.66, 47.87, 5.84, 10.98]\n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "## Getting started with the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Dataset**: RhiresD, which is a gridded daily precipitation dataset over Switzerland provided by MeteoSwiss. It is based on a spatial interpolation of rain-gauge data. The grid resolution is 1 km, but the effective resolution is in the order of 15-20 km.\n",
    "\n",
    "\n",
    "**Aggregations levels**: The gridded dataset has been averaged over different regions:\n",
    "* 12 climatic regions\n",
    "* 5 aggregated regions\n",
    "* the whole country"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read precipitation file and get events over threshold\n",
    "precip = pd.read_csv(DATADIR + '/MeteoSwiss/precip_regions.csv')\n",
    "\n",
    "df_time = pd.to_datetime({\n",
    "    'year': precip.year,\n",
    "    'month': precip.month,\n",
    "    'day': precip.day})\n",
    "precip.insert(0, \"date\", df_time, True)\n",
    "\n",
    "precip = precip[(precip.date >= DATE_START) & (precip.date <= DATE_END)]\n",
    "\n",
    "precip_p95 = precip.copy()\n",
    "precip_p99 = precip.copy()\n",
    "\n",
    "for key, ts in precip.iteritems():\n",
    "    if key in ['date', 'year', 'month', 'day']: continue\n",
    "    precip_p95[key] = ts > ts.quantile(0.95)\n",
    "    precip_p99[key] = ts > ts.quantile(0.99)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open data and get the mean value over Switzerland\n",
    "z = get_era5_data(DATADIR + '/ERA5/geopotential/*.nc', DATE_START, DATE_END)\n",
    "z500_mean = get_data_mean_over_CH_box(z, 500)\n",
    "mslp = get_era5_data(DATADIR + '/ERA5/mslp/*.nc', DATE_START, DATE_END)\n",
    "mslp_mean = get_data_mean_over_CH_box(mslp)\n",
    "t2m = get_era5_data(DATADIR + '/ERA5/Daymean_era5_T2M_EU_19790101-20210905.nc', DATE_START, DATE_END)\n",
    "t2m_mean = get_data_mean_over_CH_box(t2m)\n",
    "\n",
    "# Convert to geopotential height and hPa\n",
    "z500_mean['z'] = z500_mean['z'] / G\n",
    "mslp_mean['MSL'] = mslp_mean['MSL'] / 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the time series\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(20,5))\n",
    "z500_mean.z.plot(ax=axs[0])\n",
    "axs[0].set_title('Geopotentiel 500hPa')\n",
    "mslp_mean.MSL.plot(ax=axs[1])\n",
    "axs[1].set_title('Sea level pressure')\n",
    "t2m_mean.T2MMEAN.plot(ax=axs[2])\n",
    "axs[2].set_title('Temperature 2m')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_set = [z500_mean, mslp_mean, t2m_mean, precip]\n",
    "\n",
    "train_set, test_set = train_test_split(precip, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction of precipitation values\n",
    "\n",
    "### Using time series"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Clear session and set tf seed\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ANN using timeseries to predict precipitation\n",
    "ann_ts_precip = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"relu\", input_dim=5),\n",
    "    keras.layers.Dense(100, activation=\"relu\"), # try with elu\n",
    "    keras.layers.Dense(1, activation=\"relu\")\n",
    "])\n",
    "\n",
    "ann_ts_precip.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               1800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 32,001\n",
      "Trainable params: 32,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ann_ts_precip.compile(loss=\"mse\",\n",
    "                      optimizer=\"sgd\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "history = ann_ts_precip.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ANN using timeseries to predict extreme events\n",
    "ann_ts_precip = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"tanh\") # try with sigmoid to have the probability !\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using gridded data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ANN using gridded data to predict precipitation\n",
    "ann_ts_precip = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# ANN using gridded data to predict extreme events\n",
    "ann_ts_precip = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction of extreme events"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}