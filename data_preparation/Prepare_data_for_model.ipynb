{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import os\n",
    "# Operations on geometries\n",
    "import shapely\n",
    "import numpy as np\n",
    "import math\n",
    "import xarray as xr\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures (change the path!)\n",
    "PROJECT_ROOT_DIR = \"/Users/noeliaotero/Documents/CAS_ML/data_test/\"\n",
    "CHAPTER_ID = \"ML\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcsv(csvfiles, DATE_START, DATE_END, l_vars):\n",
    "    \"\"\"\"Read CSV files located in DIR_DATA\n",
    "        Select the time period \"\"\"\n",
    "    dataframes = []  # a list to hold all the individual pandas DataFrames\n",
    "    for ifile in range(0,len(l_files)):\n",
    "        df = pd.read_csv(l_files[ifile])\n",
    "        print(l_vars[ifile])\n",
    "        if (l_vars[ifile] == 'precip'):\n",
    "            df_time = pd.to_datetime({\n",
    "                'year': df.year,\n",
    "                'month': df.month,\n",
    "                'day': df.day})\n",
    "            df.insert(0, \"date\", df_time, True)\n",
    "            # select the total column (CH)\n",
    "            df= df[['date','reg_tot']]\n",
    "        else:\n",
    "            df = convertUnits(df, l_vars[ifile])\n",
    "            \n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d').dt.date\n",
    "        df = df[(df['date'] >= DATE_START) & (df['date'] <= DATE_END)]\n",
    "        \n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertUnits(df, mvar):\n",
    "    \"\"\"Convert each to the corresponding units\"\"\"\n",
    "    \n",
    "    if(mvar == 'T2MMEAN'):\n",
    "        df[mvar] = df[mvar] -273.15\n",
    "    elif(mvar == 'Z'):\n",
    "        df[df.columns[1:6]] = df[df.columns[1:6]]/G\n",
    "    elif (mvar == 'MSL'):\n",
    "        df[mvar] = df[mvar]/100\n",
    "        \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "G = 9.80665\n",
    "DIR_DATA = \"/Users/noeliaotero/Documents/CAS_ML/data_test/\"\n",
    "#DATE_START = '1979-01-01'\n",
    "DATE_START = pd.to_datetime('1979-01-01').date()\n",
    "#DATE_END = '2020-12-31'\n",
    "DATE_END = pd.to_datetime('2020-12-31').date()\n",
    "l_files  = glob.glob(os.path.join(DIR_DATA, '*.csv'))\n",
    "l_vars  = ['Z', 'MSL', 'T2MMEAN', 'precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(l_files[1])\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d').dt.date\n",
    "#df = df[(df['date'] >= DATE_START) & (df['date'] <= DATE_END)]\n",
    "df = df[(df['date'] >= DATE_START) & (df['date'] <= DATE_END)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z\n",
      "MSL\n",
      "T2MMEAN\n",
      "precip\n"
     ]
    }
   ],
   "source": [
    "l_all = readcsv(l_files, DATE_START, DATE_END, l_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>MSL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>1009.09700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979-01-02</td>\n",
       "      <td>1026.47890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01-03</td>\n",
       "      <td>1024.08980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-01-04</td>\n",
       "      <td>1009.13220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-01-05</td>\n",
       "      <td>1015.91220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>1004.52890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>986.39984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>996.18420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>1007.27516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1009.08950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         MSL\n",
       "0      1979-01-01  1009.09700\n",
       "1      1979-01-02  1026.47890\n",
       "2      1979-01-03  1024.08980\n",
       "3      1979-01-04  1009.13220\n",
       "4      1979-01-05  1015.91220\n",
       "...           ...         ...\n",
       "15305  2020-12-27  1004.52890\n",
       "15306  2020-12-28   986.39984\n",
       "15307  2020-12-29   996.18420\n",
       "15308  2020-12-30  1007.27516\n",
       "15309  2020-12-31  1009.08950\n",
       "\n",
       "[15310 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exceedances of precipitation\n",
    "def prec_ex(dd):\n",
    "    \n",
    "\n",
    "\n",
    "precip_p95 = precip.copy()\n",
    "precip_p99 = precip.copy()\n",
    "\n",
    "for key, ts in precip.iteritems():\n",
    "    if key in ['year', 'month', 'day']: continue\n",
    "    precip_p95[key] = ts > ts.quantile(0.95)\n",
    "    precip_p99[key] = ts > ts.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, yy_train, yy_test, attributes, ylabel):\n",
    "    \"\"\"Split the data into train and test\n",
    "        df is the data\n",
    "        attributes are the covariates \n",
    "        ylabel is the target variable\"\"\"\n",
    "    train_dataset = df[(df.date.dt.year >= yy_train[0]) & (df.date.dt.year <= yy_train[1])]\n",
    "    test_dataset = df[(df.date.dt.year >= yy_test[0]) & (df.date.dt.year <= yy_test[1])]\n",
    "    # extract the dates for each datasets\n",
    "    train_dates = train_dataset['date']\n",
    "    test_dates = test_dataset['date']\n",
    "    # extract labels\n",
    "    train_labels = train_dataset[ylabel].copy()\n",
    "    test_labels = test_dataset[ylabel].copy()\n",
    "    # extract predictors\n",
    "    train_dataset = train_dataset[attributes]\n",
    "    test_dataset = test_dataset[attributes]\n",
    "\n",
    "    return(train_dataset, train_labels, test_dataset, test_labels, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(train_dataset):\n",
    "    \n",
    "    num_attribs = list(train_dataset)\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "    ])\n",
    "\n",
    "    df_prepared = full_pipeline.fit_transform(train_dataset)\n",
    "    return(df_prepared)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
