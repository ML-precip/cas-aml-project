{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6198acf",
   "metadata": {},
   "source": [
    "# Setup\r\n",
    "\r\n",
    "Import necessary modules and define some paths and constants."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Python ≥3.5 is required\r\n",
    "import sys\r\n",
    "assert sys.version_info >= (3, 5)\r\n",
    "\r\n",
    "# Scikit-Learn ≥0.20 is required\r\n",
    "import sklearn\r\n",
    "assert sklearn.__version__ >= \"0.20\"\r\n",
    "\r\n",
    "# Common imports\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import xarray as xr\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "# To make this notebook's output stable across runs\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "# Paths\r\n",
    "DATADIR = os. getcwd() + '/../data'\r\n",
    "\r\n",
    "# Some constants\r\n",
    "CH_CENTER = [46.818, 8.228]\r\n",
    "CH_BOUNDING_BOX = [45.66, 47.87, 5.84, 10.98]\r\n",
    "\r\n",
    "# Config matplotlib\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "mpl.rc('axes', labelsize=14)\r\n",
    "mpl.rc('xtick', labelsize=12)\r\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3781a",
   "metadata": {},
   "source": [
    "# Data preparation\r\n",
    "\r\n",
    "## Target variable: precipitation time series\r\n",
    "\r\n",
    "**Dataset**: RhiresD, which is a gridded daily precipitation dataset over Switzerland provided by MeteoSwiss. It is based on a spatial interpolation of rain-gauge data. The grid resolution is 1 km, but the effective resolution is in the order of 15-20 km.\r\n",
    "\r\n",
    "\r\n",
    "**Aggregations levels**: The gridded dataset has been averaged over different regions:\r\n",
    "* 12 climatic regions\r\n",
    "* 5 aggregated regions\r\n",
    "* the whole country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Read precipitation file and get events over threshold\r\n",
    "precip = pd.read_csv(DATADIR + '/MeteoSwiss/precip_regions.csv')\r\n",
    "precip_xtreme = precip.copy()\r\n",
    "\r\n",
    "for key, ts in precip_xtreme.iteritems():\r\n",
    "    if key in ['year', 'month', 'day']: continue\r\n",
    "    precip_xtreme[key] = ts > ts.quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748c573",
   "metadata": {},
   "source": [
    "## Predictors: meteorological fields\r\n",
    "\r\n",
    "**Dataset**: ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Data extraction functions for ERA5\r\n",
    "\r\n",
    "def rename_dimensions_variables(ds):\r\n",
    "    \"\"\"Rename dimensions and attributes of the given dataset to homogenize data.\"\"\"\r\n",
    "    if hasattr(ds, 'latitude'):\r\n",
    "        ds = ds.rename({'latitude': 'lat'})\r\n",
    "    if hasattr(ds, 'longitude'):\r\n",
    "        ds = ds.rename({'longitude': 'lon'})\r\n",
    "\r\n",
    "    return ds\r\n",
    "\r\n",
    "\r\n",
    "def get_era5_data(files):\r\n",
    "    \"\"\"Extract ERA5 data for the given file(s) pattern/path.\"\"\"\r\n",
    "    ds = xr.open_mfdataset(DATADIR + '/ERA5/' + files, combine='by_coords')\r\n",
    "    ds = rename_dimensions_variables(z)\r\n",
    "\r\n",
    "    return ds\r\n",
    "\r\n",
    "    \r\n",
    "def extract_nearest_point_data(ds, lat, lon):\r\n",
    "    \"\"\"Return the time series data for the nearest grid point.\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        ds -- the dataset (xarray Dataset) to extract the data from\r\n",
    "        lat -- the latitude coordinate of the point of interest\r\n",
    "        lon -- the longitude coordinate of the point of interest\r\n",
    "\r\n",
    "    Example:\r\n",
    "    z = xr.open_mfdataset(DATADIR + '/ERA5/geopotential/*.nc', combine='by_coords')\r\n",
    "    a = extract_nearest_point_data(z, CH_CENTER[0], CH_CENTER[1])\r\n",
    "    \"\"\"\r\n",
    "    return ds.sel({'lat': lat, 'lon': lon}, method=\"nearest\")\r\n",
    "\r\n",
    "\r\n",
    "def extract_points_around(ds, lat, lon, step_lat, step_lon, nb_lat, nb_lon):\r\n",
    "    \"\"\"Return the time series data for a grid point mesh around the provided coordinates.\r\n",
    "    \r\n",
    "    Arguments:\r\n",
    "    ds -- the dataset (xarray Dataset) to extract the data from\r\n",
    "    lat -- the latitude coordinate of the center of the mesh\r\n",
    "    lon -- the longitude coordinate of the center of the mesh\r\n",
    "    step_lat -- the step in latitude of the mesh\r\n",
    "    step_lon -- the step in longitude of the mesh\r\n",
    "    nb_lat -- the total number of grid points to extract for the latitude axis (the mesh will be centered)\r\n",
    "    nb_lon -- the total number of grid points to extract for the longitude axis (the mesh will be centered)\r\n",
    "\r\n",
    "    Example:\r\n",
    "    z = xr.open_mfdataset(DATADIR + '/ERA5/geopotential/*.nc', combine='by_coords')\r\n",
    "    a = extract_points_around(z, CH_CENTER[0], CH_CENTER[1], step_lat=1, step_lon=1, nb_lat=3, nb_lon=3)\r\n",
    "    \"\"\"\r\n",
    "    lats = np.arange(lat - step_lat * (nb_lat - 1) / 2, lat + step_lat * nb_lat / 2, step_lat)\r\n",
    "    lons = np.arange(lon - step_lon * (nb_lon - 1) / 2, lon + step_lon * nb_lon / 2, step_lon)\r\n",
    "    xx, yy = np.meshgrid(lats, lons)\r\n",
    "    xx = xx.flatten()\r\n",
    "    yy = yy.flatten()\r\n",
    "    xys = np.column_stack((xx, yy))\r\n",
    "    \r\n",
    "    data = []\r\n",
    "    for xy in xys:\r\n",
    "        data.append(extract_nearest_point_data(ds, xy[0], xy[1]))\r\n",
    "    \r\n",
    "    return data\r\n",
    "\r\n",
    "def get_data_mean_over_box(ds, lats, lons, level = 0):\r\n",
    "    \"\"\"Extract data from points within a bounding box and process the mean.\r\n",
    "    \r\n",
    "    Arguments:\r\n",
    "    ds -- the dataset (xarray Dataset) to extract the data from\r\n",
    "    lats -- the min/max latitude coordinates of the bounding box\r\n",
    "    lons -- the min/max longitude coordinates of the bounding box\r\n",
    "    level -- the desired vertical level\r\n",
    "    \"\"\"\r\n",
    "    if len(lats) != 2:\r\n",
    "        raise Exception('An array of length 2 is expected for the lats.')\r\n",
    "    if len(lons) != 2:\r\n",
    "        raise Exception('An array of length 2 is expected for the lons.')\r\n",
    "\r\n",
    "    lat_start = min(lats)\r\n",
    "    lat_end = max(lats)\r\n",
    "\r\n",
    "    if (z.lat[0] > z.lat[1]):\r\n",
    "        lat_start = max(lats)\r\n",
    "        lat_end = min(lats)\r\n",
    "\r\n",
    "    ds_box = z.sel(\r\n",
    "        lat=slice(lat_start, lat_end), lon=slice(min(lons), max(lons)), level=level\r\n",
    "    )\r\n",
    "\r\n",
    "    return ds_box.mean(['lat', 'lon'])\r\n",
    "\r\n",
    "\r\n",
    "def get_data_mean_over_CH_box(ds, level = 0):\r\n",
    "    \"\"\"Extract data over the bounding box of Switzerland and return the mean time series.\r\n",
    "    \r\n",
    "    Arguments:\r\n",
    "    level -- the desired vertical level\r\n",
    "    \"\"\"\r\n",
    "    return get_data_mean_over_box(ds, [CH_BOUNDING_BOX[0], CH_BOUNDING_BOX[1]], [CH_BOUNDING_BOX[2], CH_BOUNDING_BOX[3]], level)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "16159893",
   "metadata": {},
   "source": [
    "# Unsupervised learning approaches\r\n",
    "\r\n",
    "## PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74255f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "956a4fbf",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e204ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238c93ec",
   "metadata": {},
   "source": [
    "# Supervised learning approaches\r\n",
    "\r\n",
    "## Linear regression for precipitation values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Open geopotential data and get the mean value over Switzerland\r\n",
    "z = get_era5_data('geopotential/*.nc')\r\n",
    "z_ch_mean = get_data_mean_over_CH_box(z, 500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the time series\r\n",
    "z_ch_mean.z.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "556dbb29",
   "metadata": {},
   "source": [
    "## Logistic regression for extreme events"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee0c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9261d571",
   "metadata": {},
   "source": [
    "## Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ff434a44",
   "metadata": {},
   "source": [
    "# Deep learning approaches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433be93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
