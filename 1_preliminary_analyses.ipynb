{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Python ≥3.5 is required\r\n",
    "import sys\r\n",
    "assert sys.version_info >= (3, 5)\r\n",
    "\r\n",
    "# Scikit-Learn ≥0.20 is required\r\n",
    "import sklearn\r\n",
    "assert sklearn.__version__ >= \"0.20\"\r\n",
    "\r\n",
    "# Common imports\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import xarray as xr\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "# To make this notebook's output stable across runs\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "# Paths\r\n",
    "DATADIR = os. getcwd() + '/../data'\r\n",
    "\r\n",
    "# Some constants\r\n",
    "CH_CENTER = [46.818, 8.228]\r\n",
    "CH_BOUNDING_BOX = [45.66, 47.87, 5.84, 10.98]\r\n",
    "\r\n",
    "# Config matplotlib\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "mpl.rc('axes', labelsize=14)\r\n",
    "mpl.rc('xtick', labelsize=12)\r\n",
    "mpl.rc('ytick', labelsize=12)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation\r\n",
    "\r\n",
    "## Target variable: precipitation time series\r\n",
    "\r\n",
    "**Dataset**: RhiresD, which is a gridded daily precipitation dataset over Switzerland provided by MeteoSwiss. It is based on a spatial interpolation of rain-gauge data. The grid resolution is 1 km, but the effective resolution is in the order of 15-20 km.\r\n",
    "\r\n",
    "\r\n",
    "**Aggregations levels**: The gridded dataset has been averaged over different regions:\r\n",
    "* 12 climatic regions\r\n",
    "* 5 aggregated regions\r\n",
    "* the whole country"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Read precipitation file and get events over threshold\r\n",
    "precip = pd.read_csv(DATADIR + '/MeteoSwiss/precip_regions.csv')\r\n",
    "precip_xtreme = precip.copy()\r\n",
    "\r\n",
    "for key, ts in precip_xtreme.iteritems():\r\n",
    "    if key in ['year', 'month', 'day']: continue\r\n",
    "    precip_xtreme[key] = ts > ts.quantile(0.95)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictors: meteorological fields\r\n",
    "\r\n",
    "**Dataset**: ERA5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Data extraction functions\r\n",
    "\r\n",
    "def extract_nearest_point_data(ds, lat, lon):\r\n",
    "    \"\"\"Return the time series data for the nearest grid point.\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        ds -- the dataset (xarray Dataset) to extract the data from\r\n",
    "        lat -- the latitude coordinate of the point of interest\r\n",
    "        lon -- the longitude coordinate of the point of interest\r\n",
    "\r\n",
    "    Example:\r\n",
    "    z = xr.open_mfdataset(DATADIR + '/ERA5/geopotential/*.nc', combine='by_coords')\r\n",
    "    a = extract_nearest_point_data(z, CH_CENTER[0], CH_CENTER[1])\r\n",
    "    \"\"\"\r\n",
    "    axis_lat = 'lat'\r\n",
    "    if hasattr(ds, 'latitude'):\r\n",
    "        axis_lat = 'latitude'\r\n",
    "    axis_lon = 'lon'\r\n",
    "    if hasattr(ds, 'longitude'):\r\n",
    "        axis_lon = 'longitude'\r\n",
    "\r\n",
    "    return ds.sel({axis_lat: lat, axis_lon: lon}, method=\"nearest\")\r\n",
    "\r\n",
    "\r\n",
    "def extract_points_around(ds, lat, lon, step_lat, step_lon, nb_lat, nb_lon):\r\n",
    "    \"\"\"Return the time series data for a grid point mesh around the provided coordinates.\r\n",
    "    \r\n",
    "    Arguments:\r\n",
    "    ds -- the dataset (xarray Dataset) to extract the data from\r\n",
    "    lat -- the latitude coordinate of the center of the mesh\r\n",
    "    lon -- the longitude coordinate of the center of the mesh\r\n",
    "    step_lat -- the step in latitude of the mesh\r\n",
    "    step_lon -- the step in longitude of the mesh\r\n",
    "    nb_lat -- the total number of grid points to extract for the latitude axis (the mesh will be centered)\r\n",
    "    nb_lon -- the total number of grid points to extract for the longitude axis (the mesh will be centered)\r\n",
    "\r\n",
    "    Example:\r\n",
    "    z = xr.open_mfdataset(DATADIR + '/ERA5/geopotential/*.nc', combine='by_coords')\r\n",
    "    a = extract_points_around(z, CH_CENTER[0], CH_CENTER[1], step_lat=1, step_lon=1, nb_lat=3, nb_lon=3)\r\n",
    "    \"\"\"\r\n",
    "    lats = np.arange(lat - step_lat * (nb_lat - 1) / 2, lat + step_lat * nb_lat / 2, step_lat)\r\n",
    "    lons = np.arange(lon - step_lon * (nb_lon - 1) / 2, lon + step_lon * nb_lon / 2, step_lon)\r\n",
    "    xx, yy = np.meshgrid(lats, lons)\r\n",
    "    xx = xx.flatten()\r\n",
    "    yy = yy.flatten()\r\n",
    "    xys = np.column_stack((xx, yy))\r\n",
    "    \r\n",
    "    data = []\r\n",
    "    for xy in xys:\r\n",
    "        data.append(extract_nearest_point_data(ds, xy[0], xy[1]))\r\n",
    "    \r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unsupervised learning approaches\r\n",
    "\r\n",
    "## PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-means clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised learning approaches\r\n",
    "\r\n",
    "## Linear regression for precipitation values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Open geopotential data\r\n",
    "z = xr.open_mfdataset(DATADIR + '/ERA5/geopotential/*.nc', combine='by_coords')\r\n",
    "\r\n",
    "z_ch = extract_nearest_point_data(z, CH_CENTER[0], CH_CENTER[1])\r\n",
    "\r\n",
    "print(x)\r\n",
    "\r\n",
    "#z.where(mask)#.mean('time')\r\n",
    "\r\n",
    "#z_mean\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 7.25\n",
      "    latitude   float32 45.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 7.25\n",
      "    latitude   float32 46.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 7.25\n",
      "    latitude   float32 47.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 8.25\n",
      "    latitude   float32 45.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 8.25\n",
      "    latitude   float32 46.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 8.25\n",
      "    latitude   float32 47.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 9.25\n",
      "    latitude   float32 45.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 9.25\n",
      "    latitude   float32 46.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (time: 14976, level: 5)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2020-12-31\n",
      "    longitude  float32 9.25\n",
      "    latitude   float32 47.75\n",
      "  * level      (level) int32 1000 850 700 500 300\n",
      "Data variables:\n",
      "    z          (time, level) float32 dask.array<chunksize=(365, 5), meta=np.ndarray>]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression for extreme events"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep learning approaches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}