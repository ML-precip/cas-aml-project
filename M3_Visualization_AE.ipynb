{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import time\n",
    "import math\n",
    "import imageio\n",
    "import PIL\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41766d4a",
   "metadata": {},
   "source": [
    "### Define some paths and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATADIR = os.path.join(os.getcwd(), '..', 'data')\n",
    "\n",
    "# Some constants\n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2f95c",
   "metadata": {},
   "source": [
    "# Preparing precipitation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666788e",
   "metadata": {},
   "source": [
    "RhiresD daily gridded dataset (MeteoSwiss)\n",
    "\n",
    "<img src=\"images/RhiresD.png\" alt=\"RhiresD\" height=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5ac1b",
   "metadata": {},
   "source": [
    "### Load, split and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ac12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original gridded data\n",
    "prec = xr.open_dataset(DATADIR + '/MeteoSwiss/RhiresD_ch02.lonlat_19790101_20210731.nc')\n",
    "prec = prec.sel(time=slice(DATE_START, DATE_END))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set into (training + validation) and testing based on dates\n",
    "prec_train_full = prec.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]), '{}-12-31'.format(YY_TRAIN[1])))\n",
    "prec_test = prec.sel(time=slice('{}-01-01'.format(YY_TEST[0]), '{}-12-31'.format(YY_TEST[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to numpy arrays\n",
    "X_train_full = prec_train_full.RhiresD.to_numpy()\n",
    "X_test = prec_test.RhiresD.to_numpy()\n",
    "\n",
    "# Adding the channel dimension\n",
    "X_train_full = np.expand_dims(X_train_full, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413faf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip latitude axis\n",
    "X_train_full = np.flip(X_train_full, axis=1)\n",
    "X_test = np.flip(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6717a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut border to ease use in CNN\n",
    "X_train_full = X_train_full[:, 0:100, 0:240, :]\n",
    "X_test = X_test[:, 0:100, 0:240, :]\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80020f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value/nan mask \n",
    "mask = np.isnan(X_train_full[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full training into training and validation sets (and shuffle)\n",
    "X_train, X_valid = train_test_split(X_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True)\n",
    "#X_train = (X_train - X_mean) / X_std\n",
    "#X_valid = (X_valid - X_mean) / X_std\n",
    "#X_test = (X_test - X_mean) / X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans with 0s\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_valid = np.nan_to_num(X_valid)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "img = X_train[100,:,:,0]\n",
    "img[mask] = np.nan\n",
    "#cs = ax.contourf(x, y, img, clevs, cmap=cmap, norm=norm)\n",
    "plt.set_cmap('viridis_r')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56560d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "img = X_mean.squeeze(axis=3).squeeze(axis=0)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Mean precipitation')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "img = X_std.squeeze(axis=3).squeeze(axis=0)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Std of precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c609f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Tensorflow dataset\n",
    "batch_size = 32\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(X_train).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(X_valid).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc62f1",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f97969",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=2, x_size=28, y_size=28):\n",
    "        super(CAE, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.y_size = y_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(\n",
    "                    input_shape=(self.x_size, self.y_size, 1)),\n",
    "                layers.Conv2D(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                layers.Conv2D(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(latent_dim, activation='relu'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(\n",
    "                    input_shape=(latent_dim,)),\n",
    "                layers.Dense(\n",
    "                    units=(int(self.x_size/4))*int((self.y_size/4))*32, \n",
    "                    activation='relu'),\n",
    "                layers.Reshape(\n",
    "                    target_shape=(int(self.x_size/4), int(self.y_size/4), 32)),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    kernel_size=3, \n",
    "                    strides=1, \n",
    "                    padding='same'),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = CAE(latent_dim=2, x_size=100, y_size=240)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_test, X_test,\n",
    "                epochs=30,\n",
    "                #shuffle=True,\n",
    "                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(X_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(40, 8))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    img = X_test[i]\n",
    "    img[mask] = np.nan\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"original\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    img = decoded_imgs[i]\n",
    "    img[mask] = np.nan\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"reconstructed\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_images(model, n, digit_size=28):\n",
    "  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
    "\n",
    "  norm = tfp.distributions.Normal(0, 1)\n",
    "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  image_width = digit_size*n\n",
    "  image_height = image_width\n",
    "  image = np.zeros((image_height, image_width))\n",
    "\n",
    "  for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "      z = np.array([[xi, yi]])\n",
    "      x_decoded = model.sample(z)\n",
    "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
    "      image[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(image, cmap='Greys_r')\n",
    "  plt.axis('Off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311181cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_images(autoencoder, 10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
