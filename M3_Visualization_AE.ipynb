{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import time\n",
    "import math\n",
    "import imageio\n",
    "import PIL\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41766d4a",
   "metadata": {},
   "source": [
    "### Define some paths and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATADIR = os.path.join(os.getcwd(), '..', 'data')\n",
    "\n",
    "# Some constants\n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2f95c",
   "metadata": {},
   "source": [
    "# Preparing precipitation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666788e",
   "metadata": {},
   "source": [
    "RhiresD daily gridded dataset (MeteoSwiss)\n",
    "\n",
    "<img src=\"images/RhiresD.png\" alt=\"RhiresD\" height=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5ac1b",
   "metadata": {},
   "source": [
    "### Load, split and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ac12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original gridded data\n",
    "prec = xr.open_dataset(DATADIR + '/MeteoSwiss/RhiresD_ch02.lonlat_19790101_20210731.nc')\n",
    "prec = prec.sel(time=slice(DATE_START, DATE_END))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set into (training + validation) and testing based on dates\n",
    "prec_train_full = prec.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]), '{}-12-31'.format(YY_TRAIN[1])))\n",
    "prec_test = prec.sel(time=slice('{}-01-01'.format(YY_TEST[0]), '{}-12-31'.format(YY_TEST[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to numpy arrays\n",
    "X_train_full = prec_train_full.RhiresD.to_numpy()\n",
    "X_test = prec_test.RhiresD.to_numpy()\n",
    "\n",
    "# Adding the channel dimension\n",
    "X_train_full = np.expand_dims(X_train_full, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413faf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip latitude axis\n",
    "X_train_full = np.flip(X_train_full, axis=1)\n",
    "X_test = np.flip(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6717a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut border to ease use in CNN\n",
    "X_train_full = X_train_full[:, 0:100, 0:240, :]\n",
    "X_test = X_test[:, 0:100, 0:240, :]\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80020f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value/nan mask \n",
    "mask = np.isnan(X_train_full[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full training into training and validation sets (and shuffle)\n",
    "X_train, X_valid = train_test_split(X_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True)\n",
    "#X_train = (X_train - X_mean) / X_std\n",
    "#X_valid = (X_valid - X_mean) / X_std\n",
    "#X_test = (X_test - X_mean) / X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans with 0s\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_valid = np.nan_to_num(X_valid)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "img = X_train[100,:,:,0]\n",
    "img[mask] = np.nan\n",
    "#cs = ax.contourf(x, y, img, clevs, cmap=cmap, norm=norm)\n",
    "plt.set_cmap('viridis_r')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56560d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "img = X_mean.squeeze(axis=3).squeeze(axis=0)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Mean precipitation')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "img = X_std.squeeze(axis=3).squeeze(axis=0)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Std of precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c609f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Tensorflow dataset\n",
    "batch_size = 32\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(X_train).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(X_valid).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc62f1",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f97969",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=2, x_size=28, y_size=28):\n",
    "        super(CAE, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.y_size = y_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(\n",
    "                    input_shape=(self.x_size, self.y_size, 1)),\n",
    "                layers.Conv2D(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                layers.Conv2D(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(latent_dim, activation='relu'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(\n",
    "                    input_shape=(latent_dim,)),\n",
    "                layers.Dense(\n",
    "                    units=(int(self.x_size/4))*int((self.y_size/4))*32, \n",
    "                    activation='relu'),\n",
    "                layers.Reshape(\n",
    "                    target_shape=(int(self.x_size/4), int(self.y_size/4), 32)),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    kernel_size=3, \n",
    "                    strides=1, \n",
    "                    padding='same'),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = CAE(latent_dim=2, x_size=100, y_size=240)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_test, X_test,\n",
    "                epochs=30,\n",
    "                #shuffle=True,\n",
    "                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(X_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(40, 8))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    img = X_test[i]\n",
    "    img[mask] = np.nan\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"original\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    img = decoded_imgs[i]\n",
    "    img[mask] = np.nan\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"reconstructed\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf56fc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1765d",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32081ddc",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "Architecture from Tensorflow tutorials (https://www.tensorflow.org/tutorials/generative/cvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.x_size = 100\n",
    "        self.y_size = 240\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(\n",
    "                    input_shape=(self.x_size, self.y_size, 1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=(2, 2), \n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                # No activation\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(\n",
    "                    input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(\n",
    "                    units=(int(self.x_size/4))*int((self.y_size/4))*32, \n",
    "                    activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(\n",
    "                    target_shape=(int(self.x_size/4), int(self.y_size/4), 32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    kernel_size=3, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                # No activation\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    kernel_size=3, \n",
    "                    strides=1, \n",
    "                    padding='same'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=False) # True\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23541b3",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Code from Tensorflow tutorials (https://www.tensorflow.org/tutorials/generative/cvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    \n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=x_logit, labels=x)\n",
    "    print(cross_ent.shape)\n",
    "    #logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    \n",
    "    x_pred = model.decode(z)\n",
    "    print(x_pred.shape)\n",
    "    mse = tf.keras.metrics.mean_squared_error(x, x_pred)\n",
    "    print(mse.shape)\n",
    "    logpx_z = -tf.reduce_sum(mse, axis=[1, 2, 3])\n",
    "    print(logpx_z.shape)\n",
    "    \n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf130b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87242358",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x))\n",
    "    elbo = -loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))\n",
    "    generate_and_save_images(model, epoch, test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epoch))\n",
    "plt.axis('off')  # Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98516ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a50ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_images(model, n, digit_size=28):\n",
    "  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
    "\n",
    "  norm = tfp.distributions.Normal(0, 1)\n",
    "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  image_width = digit_size*n\n",
    "  image_height = image_width\n",
    "  image = np.zeros((image_height, image_width))\n",
    "\n",
    "  for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "      z = np.array([[xi, yi]])\n",
    "      x_decoded = model.sample(z)\n",
    "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
    "      image[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "  plt.figure(figsize=(20, 15))\n",
    "  plt.imshow(image, cmap='Greys_r')\n",
    "  plt.axis('Off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413eb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_images(model, 20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
