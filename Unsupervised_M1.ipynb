{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Unsupervised learning: dimensionality reduction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Open data\n",
    "DATADIR = '../data/ERA5/'\n",
    "mslp = xr.open_mfdataset(DATADIR + 'Daymean_era5_2deg_MSL_EU_19790101-20210902.nc', combine='by_coords')\n",
    "# Convert to hPa\n",
    "mslp.MSL.values = mslp.MSL.values/100\n",
    "lon = mslp.lon\n",
    "lat = mslp.lat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mslp.MSL.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot an example (day) of mslp\n",
    "mslp.MSL.isel(time=200).plot();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#monthly_means = mslp.groupby(\"time.month\").mean()\n",
    "seas_means = mslp.groupby(\"time.season\").mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fg = seas_means.MSL.plot(col=\"season\",  col_wrap=4,\n",
    "    # The remaining kwargs customize the plot just as for not-faceted plots\n",
    "    robust=True,\n",
    "    cmap=mpl.cm.RdYlBu_r)\n",
    "\n",
    "# Use this to plot contours on each panel\n",
    "# Note that this plotting call uses the original DataArray gradients\n",
    "fg.map_dataarray(\n",
    "    xr.plot.contour, x=\"lon\", y=\"lat\", colors=\"k\", levels=13, add_colorbar=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Starting the analysis\n",
    "1. Calculate anomalies (input for PCA?)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute anomalies\n",
    "climatology = mslp.mean('time')\n",
    "# By season\n",
    "season_climatology = mslp.groupby('time.season').mean('time')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# climatological anomalies\n",
    "anom_mslp =  mslp.MSL  - climatology\n",
    "# By season\n",
    "anom_seas_mslp = mslp.groupby('time.season') - season_climatology"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# start using the whole data set for PCA. Then, anomalies can be used\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Some studies used scale-weighted by the latitude \n",
    "weights = np.cos(np.deg2rad(mslp.lat))\n",
    "weights.name = \"weights\"\n",
    "r_weights = np.sqrt(weights)\n",
    "data_mean = mslp.mean()\n",
    "# Normalised by the weights from the cosine of the latitude\n",
    "mslp_weights = (mslp - data_mean) / r_weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We need to reshape the data [time,latxlon]  \n",
    "mslp_weights_stacked = mslp_weights.stack(latlon=('lat', 'lon'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We need to reshape the data [time,latxlon]  \n",
    "mslp_stacked = mslp.stack(latlon=('lat', 'lon'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load in memory for computing the PCA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mslp_weights_stacked.load()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mslp_stacked.load()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(mslp_stacked)\n",
    "X = mslp_stacked.MSL\n",
    "XW = mslp_weights_stacked.MSL"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The number of variables (features) is 1025 (41 points in longitude * 25 points in latitude)\n",
    "# Standardise the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler  = StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pca = PCA(n_components = 4) # start with 4 \n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# See how many components \n",
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(range(1,21), pca.explained_variance_ratio_[0:20]*100)\n",
    "ax.plot(range(1,21), pca.explained_variance_ratio_[0:20]*100,'ro')\n",
    "ax.grid(ls=':')\n",
    "ax.set_xticks(range(1,21)); \n",
    "ax.set_xlabel('PC#');\n",
    "ax.set_ylabel(\"% variance\");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We can take 4 or 5\n",
    "# Following the literature I will take 4 (e.g. Cortesi et a., 2021)\n",
    "n = 12 # We can change this number\n",
    "pca.explained_variance_ratio_[:n].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Additional checks\n",
    "# pca = PCA(n_components=0.95)\n",
    "# X_reduced = pca.fit_transform(X)\n",
    "# I will beed to incllude 18 PC to get 95% \n",
    "# pca.n_components_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PCs = pca.fit_transform(X)\n",
    "PCs_n = PCs[:,:n]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data frame format for the selected components\n",
    "PCdf = pd.DataFrame(PCs_n, index = mslp['time'], \\\n",
    "                    columns = [\"PC%s\" % (x) for x in range(1, PCs_n.shape[1] +1)])\n",
    "# see the data\n",
    "PCdf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The EOFS (Empirical orthogonal functions) contain the spatial patterns associated with each PC\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "EOFs = pca.components_\n",
    "EOFs = EOFs[:n,:]\n",
    "EOFs.shape\n",
    "\n",
    "# EOFs_r = EOFs.reshape((ipc, len(lat), len(lon)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# reshape the data\n",
    "EOFs_r = EOFs.reshape((n, len(lat), len(lon)))\n",
    "EOFs_r.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nn = []\n",
    "tot_var = []\n",
    "for ip in range(n):\n",
    "    xn = pca.explained_variance_ratio_[:ip + 1].sum()\n",
    "    nn.append(xn)\n",
    "    xx =  pca.explained_variance_ratio_[:ip + 1].sum() - pca.explained_variance_ratio_[:ip ].sum()\n",
    "    tot_var.append(xx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert into Xarray for visualization\n",
    "#nn = [0,1,2,3,4]\n",
    "XD_EOFs_r = xr.DataArray(data=EOFs_r, coords=[(\"PCA\", tot_var), (\"lat\", lat), (\"lon\", lon)])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fg = XD_EOFs_r.plot(col=\"PCA\",  col_wrap=4,\n",
    "    # The remaining kwargs customize the plot just as for not-faceted plots\n",
    "    robust=True,\n",
    "    cmap=mpl.cm.RdYlBu_r)\n",
    "\n",
    "# Use this to plot contours on each panel\n",
    "# Note that this plotting call uses the original DataArray gradients\n",
    "fg.map_dataarray(\n",
    "    xr.plot.contour, x=\"lon\", y=\"lat\", colors=\"k\", levels=13, add_colorbar=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Cluster analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform K-cluster analysis using the PCds obtained before\n",
    "nclusters = 12\n",
    "kmeans = KMeans(init='k-means++', n_clusters=nclusters, n_init=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans.fit(PCdf.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans2 = KMeans(n_clusters=12, random_state=42)\n",
    "y_pred = kmeans.fit_predict(PCdf.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans.cluster_centers_\n",
    "kmeans.labels_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each day belongs to a cluster, labelled by kmeands.labels_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.unique(kmeans.labels_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = pd.DataFrame(kmeans.labels_, index=mslp['time'], columns=['cluster'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# See how many days belong to cluster 0\n",
    "index = labels.query('cluster == {}'.format(0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each cluster we calculate the mean "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_tot = len(labels.cluster)\n",
    "clusters = []\n",
    "nbdays = []\n",
    "for iclus in range(nclusters): \n",
    "    index = labels.query('cluster == {}'.format(iclus)) \n",
    "    freq = (len(index)/num_tot)*100\n",
    "    freq = round(freq,2)\n",
    "    nbdays.append(freq)\n",
    "    cluster = mslp.sel(time=index.index).mean('time')\n",
    "    clusters.append(cluster)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clusters = xr.concat(clusters, dim='cluster')\n",
    "#nbdays"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clusters.assign_coords(cluster=nbdays)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fg_C = clusters.MSL.plot(col=\"cluster\",  col_wrap=4,\n",
    "    # The remaining kwargs customize the plot just as for not-faceted plots\n",
    "    robust=True, \n",
    "    cmap=mpl.cm.RdYlBu_r)\n",
    "\n",
    "fg_C.map_dataarray(\n",
    "    xr.plot.contour, x=\"lon\", y=\"lat\", colors=\"k\", levels=13, add_colorbar=False\n",
    ")\n",
    "\n",
    "# need to change the labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}